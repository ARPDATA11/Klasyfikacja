{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T18:28:26.346870600Z",
     "start_time": "2023-05-24T18:28:25.649316300Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import sklearn\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Feature selection\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "#Model\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "\n",
    "# Model assessment\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T18:28:26.385869300Z",
     "start_time": "2023-05-24T18:28:25.677318900Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "attrition = pd.read_csv('attrition.csv')\n",
    "df1 = pd.read_csv('df1.csv')\n",
    "df2 = pd.read_csv('df2.csv')\n",
    "target = pd.read_csv('test_target.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Data check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T18:28:26.465918500Z",
     "start_time": "2023-05-24T18:28:25.728317400Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Checking the basic information for \"attition\"\n",
    "attrition.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the basic information for \"target\"\n",
    "target.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the basic information for \"df1\"\n",
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the basic information for \"df2\"\n",
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T18:28:26.468915800Z",
     "start_time": "2023-05-24T18:28:25.760828600Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Checking if data in \"df2\" contains null value\n",
    "df2.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T18:28:26.507918500Z",
     "start_time": "2023-05-24T18:28:25.791828600Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Checking basic informations for data in \"df2\"\n",
    "df2.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: it can be observed that column \"Attirtion\" in dataframe \"df2\" contains (4449-4302=147) nulls --> the same numbers of records are in dataframe \"target\", which means that the \"target\" frame may have been separated from the \"df2\" frame"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. New df creation by merging df1 and df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T18:28:26.517914800Z",
     "start_time": "2023-05-24T18:28:25.834831600Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Cration of new dataframe \"data\" by merging files: df1 and df2\n",
    "data = df1.merge(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T18:28:26.534917900Z",
     "start_time": "2023-05-24T18:28:25.867829600Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Checking basic informations for data in \"data\"\n",
    "data.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Verification of dataset basic information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T18:28:26.606432800Z",
     "start_time": "2023-05-24T18:28:25.897830500Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T18:28:26.618432100Z",
     "start_time": "2023-05-24T18:28:26.007830700Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# CSV file as archiwum, csv file consist of merged data from df1 and df2\n",
    "data.to_csv('/Users/Agnieszka/.git/Klasyfikacja/data.csv', index=True)\n",
    "data.to_csv('data.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T18:28:26.641435500Z",
     "start_time": "2023-05-24T18:28:26.252350900Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#training dataframe creation without data for test X_test\n",
    "# if target dataframe contains test data, and if \"data\" dataframe has nulls the same as in target this means that \"train\" data\n",
    "# is \"data\"-\"nulls\"\n",
    "train_DF = data.loc[data['Attrition'].notnull()]\n",
    "\n",
    "# and \"test\" data is \"data\" only with \"null\" attition\n",
    "X_test = data.loc[data['Attrition'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T18:28:26.643434Z",
     "start_time": "2023-05-24T18:28:26.290350500Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_DF"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_DF.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_DF.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column names\n",
    "columns=train_DF.columns\n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(columns)\n",
    "#therefore, number of features = 36-1=35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T18:28:26.732432500Z",
     "start_time": "2023-05-24T18:28:26.367870900Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_DF.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T18:28:26.733437400Z",
     "start_time": "2023-05-24T18:28:26.396871800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(train_DF[train_DF['NumCompaniesWorked'] == 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T18:28:26.758433Z",
     "start_time": "2023-05-24T18:28:26.454920200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#checking value in \"YearsAtCompany\" column\n",
    "train_DF['YearsAtCompany'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T18:28:26.759434700Z",
     "start_time": "2023-05-24T18:28:26.488920300Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#checking data suspicious to be outliers in column \"YearsAtCompany\"\n",
    "print(train_DF[train_DF['YearsAtCompany'] > 30])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Dupliacates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dupliacted rows\n",
    "\n",
    "duplicates_mask=train_DF.duplicated(subset=['Age', 'BusinessTravel', 'DailyRate', 'Department',\n",
    "       'DistanceFromHome', 'Education', 'EducationField', 'EmployeeCount',\n",
    "       'EnvironmentSatisfaction', 'Gender', 'HourlyRate', 'JobInvolvement',\n",
    "       'JobLevel', 'JobRole', 'JobSatisfaction', 'MaritalStatus',\n",
    "       'MonthlyIncome', 'MonthlyRate', 'NumCompaniesWorked', 'Over18',\n",
    "       'OverTime', 'PercentSalaryHike', 'PerformanceRating',\n",
    "       'RelationshipSatisfaction', 'StandardHours', 'StockOptionLevel',\n",
    "       'TotalWorkingYears', 'TrainingTimesLastYear', 'WorkLifeBalance',\n",
    "       'YearsAtCompany', 'YearsInCurrentRole', 'YearsSinceLastPromotion',\n",
    "       'YearsWithCurrManager', 'Attrition', 'YearlyIncome'])\n",
    "\n",
    "duplicated_train_DF = train_DF[duplicates_mask]\n",
    "duplicated_train_DF\n",
    "duplicated_train_DF.to_csv('Duplicates.csv')\n",
    "duplicated_train_DF.to_csv('/Users/Agnieszka/.git/Klasyfikacja/Duplicates.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#duplicates removing\n",
    "train_DF.drop_duplicates (subset=train_DF[['Age', 'BusinessTravel', 'DailyRate', 'Department',\n",
    "       'DistanceFromHome', 'Education', 'EducationField', 'EmployeeCount',\n",
    "       'EnvironmentSatisfaction', 'Gender', 'HourlyRate', 'JobInvolvement',\n",
    "       'JobLevel', 'JobRole', 'JobSatisfaction', 'MaritalStatus',\n",
    "       'MonthlyIncome', 'MonthlyRate', 'NumCompaniesWorked', 'Over18',\n",
    "       'OverTime', 'PercentSalaryHike', 'PerformanceRating',\n",
    "       'RelationshipSatisfaction', 'StandardHours', 'StockOptionLevel',\n",
    "       'TotalWorkingYears', 'TrainingTimesLastYear', 'WorkLifeBalance',\n",
    "       'YearsAtCompany', 'YearsInCurrentRole', 'YearsSinceLastPromotion',\n",
    "       'YearsWithCurrManager', 'Attrition', 'YearlyIncome']], keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#verification of train_DF dataframe after dropping duplicates (1237 duplicates removed)\n",
    "train_DF.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Unique values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T18:28:29.915370100Z",
     "start_time": "2023-05-24T18:28:29.614861Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Printing all unique values from individual columns\n",
    "for column in train_DF.columns:\n",
    "\n",
    "    unique_values = train_DF[column].unique()\n",
    "\n",
    "    print(f\"Unique value for column: {column}:\")\n",
    "\n",
    "    print(unique_values)\n",
    "\n",
    "    print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Outliers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Outliers verification through boxplots (rejecting columns without numerical data) - for train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T18:28:36.643153100Z",
     "start_time": "2023-05-24T18:28:29.665859900Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for column in train_DF.columns:\n",
    "    if(np.issubdtype(train_DF[column].dtype, np.number)):\n",
    "        plt.figure()\n",
    "        plt.boxplot(train_DF[column])\n",
    "        plt.title(column)\n",
    "        plt.xlabel('Column')\n",
    "        plt.ylabel('Value')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outliers verification for X_test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in X_test.columns:\n",
    "    if(np.issubdtype(X_test[column].dtype, np.number)):\n",
    "        plt.figure()\n",
    "        plt.boxplot(X_test[column])\n",
    "        plt.title(column)\n",
    "        plt.xlabel('Column')\n",
    "        plt.ylabel('Value')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for X_test all outliers seems to be realiable\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Boxplot analysis was performed to identify outliers in the sets\n",
    "Improbable values identified for columns: 'Age', 'DistanceFromHome', 'TotalWorkingYears', 'YearsAtCompany', 'YearsInCurrentRole', 'YearsSinceLastPromotion', 'YearsWithCurrManager'\n",
    "Due to the presence of management group in the dataset, values considered as outliers for the columns 'MonthlyIncome' and 'YearlyIncome' were considered probable and left untransformed.\n",
    "Columns 'EmployeeCount', 'Over18' and 'StandardHours' will be removed due to poor usability for the model (same values).\n",
    "Unique value for column: Over18: ['Y']\n",
    "Unique value for column: StandardHours:[80.]\n",
    "Unique value for column: EmployeeCount:[1.]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Checking the impact of outliers on the change of the median value of the entire set on the example of the 'Age' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creation of outlieres variable column\n",
    "\n",
    "outliers = train_DF[['Age', 'DistanceFromHome', 'TotalWorkingYears', 'YearsAtCompany', \n",
    "                                 'YearsInCurrentRole', 'YearsSinceLastPromotion', 'YearsWithCurrManager']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for median calculation\n",
    "def calculate_Median (data, column_name):\n",
    "    median=np.median(data)\n",
    "    print(f'{column_name}, median value: {median}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculation of median for each column in outliers\n",
    "for column in outliers.columns:\n",
    "    calculate_Median(outliers[column], column)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verification of value in column ['Age']\n",
    "train_DF['Age'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T18:28:36.725151Z",
     "start_time": "2023-05-24T18:28:36.690152200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# creation of df with realistic age (realistic age assumed nas <=60)\n",
    "df_with_real_age = train_DF.loc[train_DF['Age'] <= 60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T18:28:36.744150700Z",
     "start_time": "2023-05-24T18:28:36.705154500Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#verification of median for realistic data (Age<=60)\n",
    "df_with_real_age['Age'].describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Conclusion: the value of the median after rejecting outliers did not change significantly in relation to the median of the entire set. The median of the entire set = 36. (median for dataset with realistic age is 35) Since the percentage share of outliers in each of the columns listed in the 'outliers' frame is similar, the value of the median will also be assumed for the other columns. Due to the possibility of a logical error ('YearsAtCompany', 'YearsInCurrentRole') greater than 'Age' after replacing the outliers with the median, in the 'Age' column for outliers, the value 60 will be assumed as the upper, real limit."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing \"outliers\" in column ['Age'] by interpolation method; \n",
    "# interpolation will be the best because almost of all data for outliers are the same value as the nearest one with the same JobRole\n",
    "# Age column is treated separately because value of outliers differs from another outliers\n",
    "\n",
    "# train_DF.loc[train_DF['Age'] > 60, 'Age'] = train_DF.loc[train_DF['Age'] > 60, 'Age'].interpolate()\n",
    "# train_DF['Age'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creation of outlieres variable vithout \"Age\" column\n",
    "\n",
    "# outliers_without_age = train_DF[['DistanceFromHome', 'TotalWorkingYears', 'YearsAtCompany', 'YearsInCurrentRole', \n",
    "#                                  'YearsSinceLastPromotion', 'YearsWithCurrManager']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def outliers_removing (cols, dataFrame):\n",
    "#     for col in cols:\n",
    "#         dataFrame.loc[dataFrame[col] > 1000, col] = dataFrame.loc[dataFrame[col] > 1000, col].interpolate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpolation appears to be inappropriate method due to the adjacency of the rows also containing outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Median value for \"Age\"\n",
    "medianAge = np.median(train_DF['Age'])\n",
    "medianAge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medianAge_X_test = np.median(X_test['Age'])\n",
    "medianAge_X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outliers removing from Age column by median method\n",
    "train_DF.loc[train_DF['Age']>60, 'Age'] = medianAge\n",
    "\n",
    "# for X_test medianAge from train_DF dataset will be used as same \n",
    "X_test.loc[X_test['Age']>60, 'Age'] = medianAge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_DF['Age'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['Age'].describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replacing outliers for rest of columns without \"Age\" column"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers_without_age = train_DF[['DistanceFromHome', 'TotalWorkingYears', 'YearsAtCompany', 'YearsInCurrentRole', \n",
    "                                 'YearsSinceLastPromotion', 'YearsWithCurrManager']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for exchanging outliers (except \"Age\") to median\n",
    "def outliers_removing (cols, dataFrame):\n",
    "    for col in cols:\n",
    "        median = np.median(train_DF[col])\n",
    "        dataFrame.loc[dataFrame[col] > 1000, col] = median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers_removing(outliers_without_age, train_DF)\n",
    "outliers_removing(outliers_without_age, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe after outliers removing\n",
    "train_DF.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.describe()\n",
    "\n",
    "# outliers_without_age = train_DF[['DistanceFromHome', 'TotalWorkingYears', 'YearsAtCompany', 'YearsInCurrentRole', \n",
    "#                                  'YearsSinceLastPromotion', 'YearsWithCurrManager']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking into accout that outliers are very simillar to surroundig rows, perhaps the best way will be deletion of rows with outliers value, but first the model will be traind on outliers replaced by median"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking of histograms after outliers removing to find if now all data are realistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_DF.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_plot = ['Age', 'BusinessTravel', 'DailyRate', 'Department',\n",
    "       'DistanceFromHome', 'Education', 'EducationField',\n",
    "       'EnvironmentSatisfaction', 'Gender', 'HourlyRate', 'JobInvolvement',\n",
    "       'JobLevel', 'JobRole', 'JobSatisfaction', 'MaritalStatus',\n",
    "       'MonthlyIncome', 'MonthlyRate', 'NumCompaniesWorked', 'OverTime',\n",
    "       'PercentSalaryHike', 'PerformanceRating', 'RelationshipSatisfaction',\n",
    "       'StockOptionLevel', 'TotalWorkingYears', 'TrainingTimesLastYear',\n",
    "       'WorkLifeBalance', 'YearsAtCompany', 'YearsInCurrentRole',\n",
    "       'YearsSinceLastPromotion', 'YearsWithCurrManager', 'Attrition',\n",
    "       'YearlyIncome']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(columns_to_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histograms for train_DF\n",
    "\n",
    "fig, axes = plt.subplots(nrows=len(columns_to_plot), figsize = (5,3*len(columns_to_plot)))\n",
    "\n",
    "for i, column in enumerate (columns_to_plot):\n",
    "    sns.histplot(data=train_DF, x=column, ax=axes[i])\n",
    "    axes[i].set_title(column)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histograms for X_train\n",
    "\n",
    "fig, axes = plt.subplots(nrows=len(columns_to_plot), figsize = (5,3*len(columns_to_plot)))\n",
    "\n",
    "for i, column in enumerate (columns_to_plot):\n",
    "    sns.histplot(data=X_test, x=column, ax=axes[i])\n",
    "    axes[i].set_title(column)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Deletion of columns without any valuable data (one data for whole column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T18:28:36.978150Z",
     "start_time": "2023-05-24T18:28:36.907152700Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#X train dataframe\n",
    "\n",
    "train_DF.drop(['EmployeeCount'], axis= 1, inplace=True)\n",
    "train_DF.drop(['Over18'], axis=1, inplace=True)\n",
    "train_DF.drop(['StandardHours'], axis=1, inplace=True)\n",
    "\n",
    "# dataframe with data for testing\n",
    "\n",
    "X_test.drop(['EmployeeCount'], axis= 1, inplace=True)\n",
    "X_test.drop(['Over18'], axis=1, inplace=True)\n",
    "X_test.drop(['StandardHours'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T18:28:37.075156200Z",
     "start_time": "2023-05-24T18:28:36.937151900Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_DF.info()\n",
    "# 3 column should be removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Uniqe value to be modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T18:28:40.009152700Z",
     "start_time": "2023-05-24T18:28:39.591151800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Wypisanie wszystkich unikalnych wartości z poszczególnych kolumn\n",
    "for column in train_DF.columns:\n",
    "\n",
    "    unique_values = train_DF[column].unique()\n",
    "\n",
    "    print(f\"Unikalne wartości dla kolumny {column}:\")\n",
    "\n",
    "    print(unique_values)\n",
    "\n",
    "    print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Simple replacement"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unique values for chosen column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_encode = ['BusinessTravel', 'Department', 'EducationField', 'Gender', 'JobRole', 'MaritalStatus', 'OverTime', 'Attrition']\n",
    "\n",
    "#becasue of column \"Attition\" in X_test has NaN, incoding is not necessary and this column will be omitted\n",
    "columns_to_encode_X = ['BusinessTravel', 'Department', 'EducationField', 'Gender', 'JobRole', 'MaritalStatus', 'OverTime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_values_train_DF = train_DF[columns_to_encode].apply(lambda x: x.unique()).to_dict()\n",
    "unique_values_train_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_values_X_test = X_test[columns_to_encode_X].apply(lambda x: x.unique()).to_dict()\n",
    "unique_values_X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique_values_train_DF.to_csv('/Users/Agnieszka/.git/Klasyfikacja/uniqe_values_train_DF.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_categorical_columns(dataframe, columns):\n",
    "    for column in columns:\n",
    "        unique_values = dataframe[column].unique()\n",
    "        mapping = {value: i for i, value in enumerate(unique_values)}\n",
    "        dataframe[column] = dataframe[column].map(mapping)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_DF = encode_categorical_columns(train_DF, columns_to_encode)\n",
    "encoded_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_DF_X = encode_categorical_columns(X_test, columns_to_encode_X)\n",
    "encoded_DF_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_DF_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_values_after_encoding = train_DF[columns_to_encode].apply(lambda x: x.unique()).to_dict()\n",
    "unique_values_after_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_values_after_encoding_X = X_test[columns_to_encode].apply(lambda x: x.unique()).to_dict()\n",
    "unique_values_after_encoding_X"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Data discretization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First histogram will be show for train_DF and X_train dataset to compare and control if previous data manipulation\n",
    "has been done properly.\n",
    "\n",
    "Discretization will be performed first for train_DF than for X_test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Age column data discretization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T18:28:40.009152700Z",
     "start_time": "2023-05-24T18:28:39.623159700Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_DF['Age'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_Age = train_DF.loc[train_DF['Age']>50]\n",
    "max_Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_Age = train_DF.loc[train_DF['Age']>60]\n",
    "max_Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T18:28:40.009152700Z",
     "start_time": "2023-05-24T18:28:39.938152700Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# age division into bins for training and test data\n",
    "\n",
    "train_DF['Age_Bin'] = pd.cut(train_DF.Age, labels=['17-30', '31-45', '46-60'], bins=[17, 30, 45, 60])\n",
    "\n",
    "X_test['Age_Bin'] = pd.cut(X_test.Age, labels=['17-30', '31-45', '46-60'], bins=[17, 30, 45, 60])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_DF.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T18:28:40.053151100Z",
     "start_time": "2023-05-24T18:28:39.997153200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Age conversion from bins to numeric for train_DF\n",
    "\n",
    "\n",
    "unique_age_bin = tuple(train_DF.Age_Bin.unique())\n",
    "\n",
    "train_DF['Age_Bin'].replace(unique_age_bin, range(len(unique_age_bin)), inplace=True)\n",
    "train_DF.drop('Age', axis=1, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Age conversion from bins to numeric for X_test\n",
    "unique_age_bin_X = tuple(X_test.Age_Bin.unique())\n",
    "X_test['Age_Bin'].replace(unique_age_bin_X, range(len(unique_age_bin_X)), inplace=True)\n",
    "X_test.drop('Age', axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T18:28:40.157151900Z",
     "start_time": "2023-05-24T18:28:40.030152600Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_DF['Age_Bin'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['Age_Bin'].describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Data discretization for rested columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_DF['DailyRate'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['DailyRate'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_rate = train_DF[\"DailyRate\"]\n",
    "categories = pd.qcut(daily_rate, q=5, labels=False)\n",
    "train_DF[\"DailyRate\"] = categories\n",
    "\n",
    "\n",
    "daily_rateX = X_test[\"DailyRate\"]\n",
    "categoriesX = pd.qcut(daily_rateX, q=5, labels=False)\n",
    "X_test[\"DailyRate\"] = categoriesX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_DF['HourlyRate'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['HourlyRate'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HourlyRate = train_DF[\"HourlyRate\"]\n",
    "categories = pd.qcut(HourlyRate, q=5, labels=False)\n",
    "train_DF[\"HourlyRate\"] = categories\n",
    "\n",
    "HourlyRateX = X_test[\"HourlyRate\"]\n",
    "categoriesX = pd.qcut(HourlyRateX, q=5, labels=False)\n",
    "X_test[\"HourlyRate\"] = categoriesX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_DF['MonthlyIncome'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['MonthlyIncome'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MonthlyIncome = train_DF[\"MonthlyIncome\"]\n",
    "categories = pd.qcut(MonthlyIncome, q=5, labels=False)\n",
    "train_DF[\"MonthlyIncome\"] = categories\n",
    "\n",
    "\n",
    "MonthlyIncomeX = X_test[\"MonthlyIncome\"]\n",
    "categoriesX = pd.qcut(MonthlyIncomeX, q=5, labels=False)\n",
    "X_test[\"MonthlyIncome\"] = categoriesX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_DF['MonthlyRate'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['MonthlyRate'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MonthlyRate = train_DF[\"MonthlyRate\"]\n",
    "categories = pd.qcut(MonthlyRate, q=5, labels=False)\n",
    "train_DF[\"MonthlyRate\"] = categories\n",
    "\n",
    "\n",
    "MonthlyRateX = X_test[\"MonthlyRate\"]\n",
    "categoriesX = pd.qcut(MonthlyRateX, q=5, labels=False)\n",
    "X_test[\"MonthlyRate\"] = categoriesX\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_DF['YearlyIncome'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['YearlyIncome'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YearlyIncome = train_DF[\"YearlyIncome\"]\n",
    "categories = pd.qcut(YearlyIncome, q=5, labels=False)\n",
    "train_DF[\"YearlyIncome\"] = categories\n",
    "\n",
    "YearlyIncomeX = X_test[\"YearlyIncome\"]\n",
    "categoriesX = pd.qcut(YearlyIncomeX, q=5, labels=False)\n",
    "X_test[\"YearlyIncome\"] = categoriesX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_DF.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_DF.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_show = list(train_DF.columns)\n",
    "columns_to_show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histograms after feature engeeniring\n",
    "\n",
    "fig, axes = plt.subplots(nrows=len(columns_to_show), figsize = (5,3*len(columns_to_show)))\n",
    "\n",
    "for i, column in enumerate (columns_to_show):\n",
    "    sns.histplot(data=train_DF, x=column, ax=axes[i])\n",
    "    axes[i].set_title(column)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histograms after feature engeeniring\n",
    "\n",
    "fig, axes = plt.subplots(nrows=len(columns_to_show), figsize = (5,3*len(columns_to_show)))\n",
    "\n",
    "for i, column in enumerate (columns_to_show):\n",
    "    sns.histplot(data=X_test, x=column, ax=axes[i])\n",
    "    axes[i].set_title(column)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of the significance of variables based on regression coefficients"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation verification after EDA and feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25,20))\n",
    "sns.set_theme(style=\"white\")\n",
    "corr = train_DF.corr()\n",
    "heatmap = sns.heatmap(corr, annot=True, cmap=\"Blues\", fmt='.1g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Correlation_for_Attition=corr['Attrition']\n",
    "Correlation_for_Attition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation to absolute value transformation and sorting\n",
    "\n",
    "Correlation_sorted = np.absolute(Correlation_for_Attition).sort_values()\n",
    "Correlation_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Correlation_sorted_50perc = Correlation_sorted>0.5\n",
    "Correlation_sorted_50perc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "significant_variable = Correlation_sorted[Correlation_sorted>0.5]\n",
    "significant_variable"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X_train, y_train, X_test, y_test preparation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from train_DF following will be prepared\n",
    "X_train = train_DF-train_DF['Attrition']\n",
    "y_train = train_DF['Attrition']\n",
    "///\n",
    "from X_test following will be prepared\n",
    "X_test = X_test - X_test['Attrition']\n",
    "y_test = target['Attrition]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test preparation. y_test is the column ['Attrition] from test_target.csv file (variable \"target\" prepared at the begining\n",
    "# the order of operations is important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_DF['Attrition']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_DF.drop('Attrition', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = target['Attrition']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.drop('Attrition',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First simply model to check significance of variables _ ALL VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(target, prediction, average='weighted'):\n",
    "    accuracy = accuracy_score(target, prediction)\n",
    "    precision = precision_score(target, prediction, average=average)\n",
    "    recall = recall_score(target, prediction, average=average)\n",
    "    f1 = f1_score(target, prediction, average=average)\n",
    "    mislabeled = (target != prediction).sum()\n",
    "    total = len(target)\n",
    "    return accuracy, precision, recall, f1, mislabeled, total\n",
    "\n",
    "def print_results(metrics):\n",
    "    print(f'  Accuracy:  {metrics[0]}')\n",
    "    print(f'  Precision: {metrics[1]}')\n",
    "    print(f'  Recall:    {metrics[2]}')\n",
    "    print(f'  F1 score:  {metrics[3]}')\n",
    "    print(f'  Mislabeled {metrics[4]} out of {metrics[5]}')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "def train_model(model, grid_search_params):\n",
    "  pipe = Pipeline(steps=[(\"scaler\", scaler), (\"model\", model)])\n",
    "  grid_pipeline = GridSearchCV(pipe, grid_search_params)\n",
    "  # fit\n",
    "  grid_pipeline.fit(X_train, y_train)\n",
    "  print(\"Best CV accuracy train\", grid_pipeline.best_score_)\n",
    "  print(\"Best CV params\", grid_pipeline.best_params_)\n",
    "  \n",
    "  pred = grid_pipeline.predict(X_test)\n",
    "  metrics = calculate_metrics(y_test, pred)\n",
    "  print_results(metrics)\n",
    "  return grid_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree = DecisionTreeClassifier()\n",
    "decision_tree_grid_search_params = {}\n",
    "\n",
    "grid_search_decision_tree = train_model(decision_tree, decision_tree_grid_search_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = grid_search_decision_tree.best_estimator_[\"model\"].feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating importances_df dataframe\n",
    "importances_df = pd.DataFrame({\"feature_names\" : X_train.columns.tolist(), \n",
    "                               \"importances\" : importances})\n",
    "                             \n",
    "# Plotting bar chart, g is from graph\n",
    "fig, ax = plt.subplots(figsize=(25, 10))\n",
    "g = sns.barplot(x=importances_df[\"feature_names\"], \n",
    "                y=importances_df[\"importances\"],\n",
    "                ax=ax\n",
    ")\n",
    "g.set_title(\"Feature importances\", fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating importances_df dataframe\n",
    "importances_df = pd.DataFrame({\"feature_names\" : X_train.columns.tolist(), \n",
    "                               \"importances\" : importances})\n",
    "                             \n",
    "# Plotting bar chart, g is from graph\n",
    "fig, ax = plt.subplots(figsize=(25, 10))\n",
    "g = sns.barplot(x=importances_df[\"feature_names\"], \n",
    "                y=importances_df[\"importances\"],\n",
    "                ax=ax\n",
    ")\n",
    "g.set_title(\"Feature importances\", fontsize=14)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recursive Feature Elimination for Decision Tree Classifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree Classifier for all variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_DTC = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" checked><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 485,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_DTC.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_train= model_DTC.predict(X_train)\n",
    "y_predict_test = model_DTC.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(target, prediction, average='weighted'):\n",
    "    accuracy = accuracy_score(target, prediction)\n",
    "    precision = precision_score(target, prediction, average=average)\n",
    "    recall = recall_score(target, prediction, average=average)\n",
    "    f1 = f1_score(target, prediction, average=average)\n",
    "    mislabeled = (target != prediction).sum()\n",
    "    total = len(target)\n",
    "    return accuracy, precision, recall, f1, mislabeled, total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(metrics, classifier_id='classifier'):\n",
    "    print(f'Results for {classifier_id}')\n",
    "    print('----')\n",
    "    print(f'  Accuracy:  {metrics[0]}')\n",
    "    print(f'  Precision: {metrics[1]}')\n",
    "    print(f'  Recall:    {metrics[2]}')\n",
    "    print(f'  F1 score:  {metrics[3]}')\n",
    "    print(f'  Mislabeled {metrics[4]} out of {metrics[5]}')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Decision_Tree_all_variables_train\n",
      "----\n",
      "  Accuracy:  1.0\n",
      "  Precision: 1.0\n",
      "  Recall:    1.0\n",
      "  F1 score:  1.0\n",
      "  Mislabeled 0 out of 3065\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Metrics for train data\n",
    "print_results(calculate_metrics(y_train, y_predict_train), 'Decision_Tree_all_variables_train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Decision_Tree_all_variables_test\n",
      "----\n",
      "  Accuracy:  0.3741496598639456\n",
      "  Precision: 0.7080383173677635\n",
      "  Recall:    0.3741496598639456\n",
      "  F1 score:  0.42932613380846046\n",
      "  Mislabeled 92 out of 147\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Metrics for test data\n",
    "print_results(calculate_metrics(y_test, y_predict_test), 'Decision_Tree_all_variables_test')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recursive Feature Elimination "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_RFE = RFE(model_DTC, n_features_to_select = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [],
   "source": [
    "RFE_fit = model_RFE.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False, False, False,  True, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False,  True,\n",
       "       False,  True, False, False, False,  True, False, False, False,\n",
       "        True, False,  True, False, False])"
      ]
     },
     "execution_count": 493,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RFE_fit.support_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['EmployeeNumber', 'DistanceFromHome', 'NumCompaniesWorked',\n",
       "       'PercentSalaryHike', 'TotalWorkingYears', 'YearsInCurrentRole',\n",
       "       'YearsWithCurrManager'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 494,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "significant_variables_acc_RFE = X_train.columns[RFE_fit.support_]\n",
    "significant_variables_acc_RFE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree Classifier for RFE significant variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = ['EmployeeNumber', 'DistanceFromHome', 'JobRole', 'NumCompaniesWorked',\n",
    "       'PercentSalaryHike', 'TotalWorkingYears', 'YearsAtCompany']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_RFE = X_train[selected_columns]\n",
    "X_test_RFE = X_test[selected_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_DTC_RFE_variables = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" checked><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 498,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_DTC_RFE_variables.fit(X_train_RFE, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_RFE_variables_train = model_DTC_RFE_variables.predict(X_train_RFE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_RFE_variables_test = model_DTC_RFE_variables.predict(X_test_RFE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Decision_Tree_RFE_Significant_variables_train\n",
      "----\n",
      "  Accuracy:  1.0\n",
      "  Precision: 1.0\n",
      "  Recall:    1.0\n",
      "  F1 score:  1.0\n",
      "  Mislabeled 0 out of 3065\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_results(calculate_metrics(y_train, y_predict_RFE_variables_train), 'Decision_Tree_RFE_Significant_variables_train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Decision_Tree_RFE_Significant_variables_test\n",
      "----\n",
      "  Accuracy:  0.3741496598639456\n",
      "  Precision: 0.800060171488743\n",
      "  Recall:    0.3741496598639456\n",
      "  F1 score:  0.406784952787085\n",
      "  Mislabeled 92 out of 147\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_results(calculate_metrics(y_test, y_predict_RFE_variables_test), 'Decision_Tree_RFE_Significant_variables_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
